{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC NAME\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This guide will show you how to:\n",
    "\n",
    "* TODO\n",
    "* TODO\n",
    "\n",
    "By the end of it, you will TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neptune-client TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: TODO\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_epochs =12\n",
    "logdir = 'exps'\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "loaders = collections.OrderedDict()\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True,\n",
    "    download=True, transform=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False,\n",
    "    download=True, transform=data_transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size,\n",
    "    shuffle=False, num_workers=num_workers)\n",
    "\n",
    "loaders['train'] = trainloader\n",
    "loaders['valid'] = testloader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "from catalyst.contrib.dl.callbacks.neptune import NeptuneLogger\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_token='ANONYMOUS',  # your Neptune token\n",
    "    project_name='shared/catalyst-integration',\n",
    "    offline_mode=False,  # turn off neptune for debug\n",
    "    name='catalyst-example',\n",
    "    params={'batch_size': batch_size,\n",
    "            'epoch_nr': num_epochs,\n",
    "            'num_workers': num_workers},  # your hyperparameters, immutable\n",
    "    properties={'data_source': 'cifar10'},  # mutable\n",
    "    tags=['resnet', 'no-augmentations'],  # tags\n",
    "    upload_source_files=['catalyst_example.py'],  # files to save, grep-like\n",
    ")\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "runner = SupervisedRunner()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True,\n",
    "    callbacks=[neptune_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Neptune\n",
    "\n",
    "Connects your script to Neptune application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "neptune.init(\n",
    "    api_token=\"ANONYMOUS\",\n",
    "    project_qualified_name=\"shared/onboarding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You tell Neptune: \n",
    "\n",
    "* **who you are**: your Neptune API token `api_token` \n",
    "* **where you want to send your data**: your Neptune project `project_qualified_name`.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** \n",
    "\n",
    "\n",
    "Instead of logging data to the public project 'shared/onboarding' as an anonymous user 'neptuner' you can log it to your own project.\n",
    "\n",
    "To do that:\n",
    "\n",
    "1. Get your Neptune API token\n",
    "\n",
    "![image](https://neptune.ai/wp-content/uploads/get_token.gif)\n",
    "\n",
    "2. Pass the token to ``api_token`` argument of ``neptune.init()`` method: ``api_token=YOUR_API_TOKEN``\n",
    "3. Pass your username to the ``project_qualified_name`` argument of the ``neptune.init()`` method: ``project_qualified_name='YOUR_USERNAME/sandbox``. Keep `/sandbox` at the end, the `sandbox` project that was automatically created for you.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "neptune.init(project_qualified_name='funky_steve/sandbox', \n",
    "             api_token='eyJhcGlfYW908fsdf23f940jiri0bn3085gh03riv03irn',\n",
    "            )\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.create_experiment(name='great-idea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This opens a new \"experiment\" namespace in Neptune to which you can log various objects.\n",
    "\n",
    "Click on the link above to open this experiment in Neptune.\n",
    "\n",
    "For now it is empty but keep the tab with experiment open to see what happens next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: TODO\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note:**\n",
    "   \n",
    "When you track experiments with Neptune in Jupyter notebooks you need to explicitly stop the experiment by running `neptune.stop()`.\n",
    "\n",
    "If you are running Neptune in regular `.py` scripts it will stop automatically when your code stops running.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37",
   "language": "python",
   "name": "py_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
